{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8892629e",
   "metadata": {},
   "source": [
    "# Step 1: Web Scraping\n",
    "Here, we use an api from [Pushshift.io](https://github.com/pushshift/api) to scrape Reddit posts and convert them to a JSON file.  \n",
    "**NOTE:** This notebook will take approximately 6h to run to completion, though this can be reduced by changing the date range in cell #3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8990f417",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_POSTS = 1000\n",
    "\n",
    "def getUrl(start, end):\n",
    "    startEpoch = int(start.timestamp())\n",
    "    endEpoch = int(end.timestamp())\n",
    "    return f'https://api.pushshift.io/reddit/submission/search/?size={N_POSTS}&after={startEpoch}&before={endEpoch}&sort_type=score&sort=desc&subreddit=stocks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e8c18fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/40748687/python-api-rate-limiting-how-to-limit-api-calls-globally\n",
    "import requests\n",
    "import json\n",
    "\n",
    "CALLS = 60\n",
    "RATE_LIMIT = 60\n",
    "\n",
    "#@sleep_and_retry\n",
    "#@limits(calls=CALLS, period=RATE_LIMIT)\n",
    "def getData(urlStr):\n",
    "    response = requests.get(urlStr)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('API response: {}'.format(response.status_code))\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "002f4ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-01-01.json done\n",
      "2013-01-02.json done\n"
     ]
    }
   ],
   "source": [
    "# GET /hello/world\n",
    "#https://stackoverflow.com/questions/1060279/iterating-through-a-range-of-dates-in-python\n",
    "from datetime import date, timedelta, datetime\n",
    "import time\n",
    "\n",
    "def daterange(start_date, end_date):\n",
    "    for n in range(int((end_date - start_date).days)):\n",
    "        yield ((start_date + timedelta(n)), (start_date + timedelta(n+1)))\n",
    "\n",
    "start_date = datetime(2013, 1, 1)\n",
    "end_date = datetime(2013, 1, 3)\n",
    "\n",
    "    \n",
    "for (start, end) in daterange(start_date, end_date):\n",
    "    while True:\n",
    "        try:\n",
    "            data = getData(getUrl(start, end))['data']\n",
    "            filename = start.strftime(\"%Y-%m-%d\") + '.json'\n",
    "            with open('../data/out/' + filename, 'w') as f:\n",
    "                f.write(json.dumps(data))\n",
    "            print(filename + ' done')\n",
    "        except Exception as e:\n",
    "            time.sleep(.1)\n",
    "            continue\n",
    "        break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "292dd54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_key = 'r8zf7RTqSoHCq8Wiidi81Q'\n",
    "secret_key = 'LtxuY4A-ur1SWt-HLT7xS1qgoFon_g'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b03d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=public_key,\n",
    "    client_secret=secret_key,\n",
    "    user_agent=\"my user agent\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34fb7248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataForSumbission(submission):\n",
    "    submission.comments.replace_more(limit=None)\n",
    "    datas = []\n",
    "    for comment in submission.comments.list():\n",
    "        data = {}\n",
    "        data['time'] = comment.created_utc\n",
    "        data['submission_id'] = submission.id\n",
    "        data['comment_id'] = comment.id\n",
    "        data['body'] = comment.body\n",
    "        data['score'] = comment.score\n",
    "        data['num_replies'] = len(comment.replies)\n",
    "        data['is_root'] = 1 if comment.is_root else 0\n",
    "        data['submission_score'] = submission.score\n",
    "        data['submission_ratio'] = comment.score/submission.score if submission.score != 0 else 100\n",
    "        data['submission_title'] = submission.title\n",
    "        data['submission_text'] = submission.selftext\n",
    "        if not comment.is_root:\n",
    "            parent = comment.parent()\n",
    "            data['parent_text'] = parent.body\n",
    "            data['parent_score'] = parent.score\n",
    "            data['parent_ratio'] = comment.score/parent.score if parent.score != 0 else -999\n",
    "        else:\n",
    "            data['parent_text'] = submission.title + ' ' + submission.selftext\n",
    "            data['parent_score'] = data['submission_score']\n",
    "            data['parent_ratio'] = data['submission_ratio']        \n",
    "        \n",
    "        datas.append(data)\n",
    "\n",
    "    return datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "661b2ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 2013-01-01.json\n",
      "2: 2013-01-02.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "i = 0\n",
    "for file in os.listdir(\"../data/out/\")[:]:\n",
    "    i += 1\n",
    "    with open('../data/out/' + file) as f:\n",
    "        datas = json.load(f)\n",
    "        output = []\n",
    "        for data in datas:\n",
    "            url = data['full_link']\n",
    "            id = data['id']\n",
    "            submission = reddit.submission(id=id)\n",
    "            result = getDataForSumbission(submission)\n",
    "            output.extend(result)\n",
    "        with open('../data/comments/' + file, 'w') as f:\n",
    "            f.write(json.dumps(output))\n",
    "    print(str(i) + ': ' + file)\n",
    "    #break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
